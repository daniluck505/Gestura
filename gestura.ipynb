{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "from pynput.mouse import Controller, Button\n",
    "from screeninfo import get_monitors\n",
    "from collections import deque, Counter\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyyaml in ./.venv/lib/python3.12/site-packages (6.0.2)\n"
     ]
    }
   ],
   "source": [
    "# !pip install pynput\n",
    "# !pip install torch\n",
    "# !pip install numpy\n",
    "# !pip install opencv-python\n",
    "# !pip install ultralytics\n",
    "# !pip install matplotlib\n",
    "# !pip install screeninfo\n",
    "# !pip install pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gestura:\n",
    "    def __init__(self, model_weights, camera_index, buffer_size=5, scale=0.1, speed=0.3, \n",
    "                 conf=0.7, iou=0.5, device='cpu', frame_size=(720, 480), see=False):\n",
    "        self.model = YOLO(model_weights)\n",
    "        self.camera_index = camera_index\n",
    "        self.confidence = conf\n",
    "        self.iou_threshold = iou\n",
    "        self.device = device\n",
    "        self.frame_size = frame_size\n",
    "        self.mouse_controller = Controller()\n",
    "        self.scale_factor = scale\n",
    "        self.movement_speed = speed\n",
    "        self.see = see\n",
    "        \n",
    "        self._initialize_buffers(buffer_size)\n",
    "        self._initialize_monitor_info()\n",
    "        self._initialize_control_area()\n",
    "        \n",
    "    def _initialize_buffers(self, buffer_size):\n",
    "        self.buffer = {\n",
    "            'x': deque(maxlen=buffer_size),\n",
    "            'y': deque(maxlen=buffer_size),\n",
    "            'bbox': deque(maxlen=buffer_size),\n",
    "            'classes': deque(maxlen=buffer_size)\n",
    "        }\n",
    "        \n",
    "    def _initialize_monitor_info(self):\n",
    "        self.primary_monitor = next((m for m in get_monitors() if m.is_primary), get_monitors()[0])\n",
    "        self.screen_width, self.screen_height = self.primary_monitor.width, self.primary_monitor.height\n",
    "    \n",
    "    def _initialize_control_area(self):\n",
    "        \"\"\"Initialize control area with default values that will be updated during detection\"\"\"\n",
    "        self.control_area = {\n",
    "            'x1': 0,\n",
    "            'y1': 0,\n",
    "            'width': 1,\n",
    "            'height': 1  \n",
    "        }\n",
    "    \n",
    "    def predict_hands(self, image):\n",
    "        return self.model.predict(\n",
    "            image, \n",
    "            device=self.device, \n",
    "            conf=self.confidence, \n",
    "            iou=self.iou_threshold, \n",
    "            verbose=False\n",
    "        )[0]\n",
    "    \n",
    "    def process_detections(self, image, detections):\n",
    "        for detection in detections:\n",
    "            bboxes = detection.boxes.xyxy.cpu().int().tolist()\n",
    "            class_ids = detection.boxes.cls.cpu().int().tolist()\n",
    "            \n",
    "            for bbox, class_id in zip(bboxes, class_ids):\n",
    "                self._update_buffers(bbox, class_id)\n",
    "                self._update_control_area(image, bbox)\n",
    "                if self.see:\n",
    "                    self._draw_detection(image)\n",
    "                self._control_cursor(class_id)\n",
    "                \n",
    "        return image\n",
    "    \n",
    "    def _update_buffers(self, bbox, class_id):\n",
    "        x_min, y_min, x_max, y_max = bbox\n",
    "        center_x, center_y = (x_min + x_max) // 2, (y_min + y_max) // 2\n",
    "        \n",
    "        self.buffer['bbox'].append(bbox)\n",
    "        self.buffer['classes'].append(class_id)\n",
    "        self.buffer['x'].append(center_x)\n",
    "        self.buffer['y'].append(center_y)\n",
    "    \n",
    "    def _update_control_area(self, image, bbox):\n",
    "        \"\"\"Calculate and update control area based on current bbox\"\"\"\n",
    "        x_min, y_min, x_max, y_max = bbox\n",
    "        offset_x = int((x_max - x_min) * (1 + self.scale_factor) / 2)\n",
    "        offset_y = int((y_max - y_min) * (1 + self.scale_factor) / 2)\n",
    "        \n",
    "        control_area_x1 = offset_x\n",
    "        control_area_y1 = offset_y\n",
    "        control_area_x2 = image.shape[1] - offset_x\n",
    "        control_area_y2 = image.shape[0] - offset_y\n",
    "        \n",
    "        self.control_area = {\n",
    "            'x1': control_area_x1,\n",
    "            'y1': control_area_y1,\n",
    "            'width': max(control_area_x2 - control_area_x1, 1),\n",
    "            'height': max(control_area_y2 - control_area_y1, 1)\n",
    "        }\n",
    "    \n",
    "    def _draw_detection(self, image):\n",
    "        if not self.buffer['bbox']:\n",
    "            return\n",
    "            \n",
    "        avg_bbox = self._calculate_average_bbox()\n",
    "        x_min, y_min, x_max, y_max = avg_bbox\n",
    "        \n",
    "        cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 0, 255), 2)\n",
    "        \n",
    "        class_name = self.model.names[self._most_common_class()]\n",
    "        label = f\"{class_name} (ID: {self._most_common_class()})\"\n",
    "        cv2.putText(image, label, (x_min, y_min - 10), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "        \n",
    "        center_x, center_y = self._calculate_average_position()\n",
    "        cv2.circle(image, (center_x, center_y), 3, (0, 0, 255), -1)\n",
    "        \n",
    "        self._draw_control_area_visual(image)\n",
    "    \n",
    "    def _draw_control_area_visual(self, image):\n",
    "        \"\"\"Draw control area visualization (only for visual purposes)\"\"\"\n",
    "        cv2.rectangle(image, \n",
    "                     (self.control_area['x1'], self.control_area['y1']),\n",
    "                     (self.control_area['x1'] + self.control_area['width'], \n",
    "                      self.control_area['y1'] + self.control_area['height']),\n",
    "                     (0, 255, 0), 2)\n",
    "    \n",
    "    def _calculate_average_bbox(self):\n",
    "        bboxes = list(self.buffer['bbox'])\n",
    "        avg_x_min = sum(b[0] for b in bboxes) // len(bboxes)\n",
    "        avg_y_min = sum(b[1] for b in bboxes) // len(bboxes)\n",
    "        avg_x_max = sum(b[2] for b in bboxes) // len(bboxes)\n",
    "        avg_y_max = sum(b[3] for b in bboxes) // len(bboxes)\n",
    "        return (avg_x_min, avg_y_min, avg_x_max, avg_y_max)\n",
    "    \n",
    "    def _calculate_average_position(self):\n",
    "        return (int(sum(self.buffer['x']) / len(self.buffer['x'])), \n",
    "                int(sum(self.buffer['y']) / len(self.buffer['y'])))\n",
    "    \n",
    "    def _most_common_class(self):\n",
    "        return Counter(self.buffer['classes']).most_common(1)[0][0]\n",
    "    \n",
    "    def _control_cursor(self, class_id):\n",
    "        if class_id == 18:\n",
    "            self._move_cursor()\n",
    "    \n",
    "    def _move_cursor(self):\n",
    "        if not self.buffer['x']:\n",
    "            return\n",
    "            \n",
    "        avg_x, avg_y = self._calculate_average_position()\n",
    "        \n",
    "        norm_x = (avg_x - self.control_area['x1']) / self.control_area['width']\n",
    "        norm_y = (avg_y - self.control_area['y1']) / self.control_area['height']\n",
    "        \n",
    "        target_x = norm_x * self.screen_width\n",
    "        target_y = norm_y * self.screen_height\n",
    "        \n",
    "        current_x, current_y = self.mouse_controller.position\n",
    "        new_x = current_x + (target_x - current_x) * self.movement_speed\n",
    "        new_y = current_y + (target_y - current_y) * self.movement_speed\n",
    "        \n",
    "        new_x = max(0, min(new_x, self.screen_width))\n",
    "        new_y = max(0, min(new_y, self.screen_height))\n",
    "        \n",
    "        self.mouse_controller.position = (new_x, new_y)\n",
    "    \n",
    "    def run(self):\n",
    "        cap = cv2.VideoCapture(self.camera_index)\n",
    "        if not cap.isOpened():\n",
    "            raise RuntimeError('Не удалось открыть камеру')\n",
    "            \n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, self.frame_size[0])\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, self.frame_size[1])\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                success, frame = cap.read()\n",
    "                if not success:\n",
    "                    raise RuntimeError('Не удалось получить кадр с камеры')\n",
    "                \n",
    "                frame = cv2.flip(frame, 1)\n",
    "                detections = self.predict_hands(frame)\n",
    "                if self.see:\n",
    "                    processed_frame = self.process_detections(frame, detections)\n",
    "                    cv2.imshow('Hand Detection', processed_frame)\n",
    "                else:\n",
    "                    self.process_detections(frame, detections)\n",
    "                \n",
    "                if self.see and (cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "                    break\n",
    "        finally:\n",
    "            cap.release()\n",
    "            if self.see:\n",
    "                cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 10:51:47.765 Python[46853:5667456] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n",
      "2025-03-25 10:51:50.280 Python[46853:5667456] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-03-25 10:51:50.280 Python[46853:5667456] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    }
   ],
   "source": [
    "detector = Gestura('YOLOv10n_gestures.pt', camera_index=2,\n",
    "                   buffer_size=8, scale=0.2, speed=0.2, see=True)\n",
    "detector.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gestura:\n",
    "    def __init__(self, model_weights, camera_index, buffer_size=5, scale=0.1, speed=0.3, conf=0.7, iou=0.5, device='cpu', frame_size=(720, 480)):\n",
    "        self.model = YOLO(model_weights)\n",
    "        self.camera_index = camera_index\n",
    "        self.confidence = conf\n",
    "        self.iou_threshold = iou\n",
    "        self.device = device\n",
    "        self.frame_size = frame_size\n",
    "        self.mouse_controller = Controller()\n",
    "        self.scale_factor = scale\n",
    "        self.movement_speed = speed\n",
    "\n",
    "        self.buffer = {'x': deque(maxlen=buffer_size), 'y': deque(maxlen=buffer_size), 'bbox': deque(maxlen=buffer_size), 'classes': deque(maxlen=buffer_size)}\n",
    "        monitor = next((m for m in get_monitors() if m.is_primary), get_monitors()[0])\n",
    "        self.screen_width, self.screen_height = monitor.width, monitor.height\n",
    "        self.control_area = {'x1': 0, 'y1': 0, 'width': 1, 'height': 1}\n",
    "\n",
    "        self.clicked = False\n",
    "        self.dragging = False\n",
    "        self.exit = False\n",
    "\n",
    "    def predict_hands(self, image):\n",
    "        return self.model.predict(image, device=self.device, conf=self.confidence, iou=self.iou_threshold, verbose=False)[0]\n",
    "\n",
    "    def process_detections(self, detections, image_shape):\n",
    "        ids_detected = set()\n",
    "\n",
    "        for detection in detections:\n",
    "            for bbox, class_id in zip(detection.boxes.xyxy.cpu().int().tolist(), detection.boxes.cls.cpu().int().tolist()):\n",
    "                x_min, y_min, x_max, y_max = bbox\n",
    "                center_x, center_y = (x_min + x_max) // 2, (y_min + y_max) // 2\n",
    "                self.buffer['bbox'].append(bbox)\n",
    "                self.buffer['classes'].append(class_id)\n",
    "                self.buffer['x'].append(center_x)\n",
    "                self.buffer['y'].append(center_y)\n",
    "                self._update_control_area(image_shape, bbox)\n",
    "\n",
    "                ids_detected.add(class_id)\n",
    "\n",
    "                if class_id == 18:\n",
    "                    self._move_cursor()\n",
    "                    self.clicked = False\n",
    "\n",
    "                if class_id == 14 and not self.clicked:\n",
    "                    self._left_click()\n",
    "                    self.clicked = True\n",
    "\n",
    "                if class_id in {28, 29}:\n",
    "                    if not self.dragging:\n",
    "                        self._start_drag()\n",
    "                    self._move_cursor()\n",
    "\n",
    "        if not ids_detected.intersection({28, 29}) and self.dragging:\n",
    "            self._stop_drag()\n",
    "\n",
    "        if 2 in ids_detected:\n",
    "            self.exit = True\n",
    "            \n",
    "\n",
    "    def _update_control_area(self, image_shape, bbox):\n",
    "        x_min, y_min, x_max, y_max = bbox\n",
    "        offset_x = int((x_max - x_min) * (1 + self.scale_factor) / 2)\n",
    "        offset_y = int((y_max - y_min) * (1 + self.scale_factor) / 2)\n",
    "        self.control_area['x1'] = offset_x\n",
    "        self.control_area['y1'] = offset_y\n",
    "        self.control_area['width'] = max(image_shape[1] - 2 * offset_x, 1)\n",
    "        self.control_area['height'] = max(image_shape[0] - 2 * offset_y, 1)\n",
    "\n",
    "    def _move_cursor(self):\n",
    "        avg_x = sum(self.buffer['x']) / len(self.buffer['x'])\n",
    "        avg_y = sum(self.buffer['y']) / len(self.buffer['y'])\n",
    "        norm_x = (avg_x - self.control_area['x1']) / self.control_area['width']\n",
    "        norm_y = (avg_y - self.control_area['y1']) / self.control_area['height']\n",
    "        target_x = norm_x * self.screen_width\n",
    "        target_y = norm_y * self.screen_height\n",
    "        current_x, current_y = self.mouse_controller.position\n",
    "        new_x = max(0, min(current_x + (target_x - current_x) * self.movement_speed, self.screen_width))\n",
    "        new_y = max(0, min(current_y + (target_y - current_y) * self.movement_speed, self.screen_height))\n",
    "        self.mouse_controller.position = (new_x, new_y)\n",
    "\n",
    "    def _left_click(self):\n",
    "        self.mouse_controller.click(Button.left)\n",
    "\n",
    "    def _start_drag(self):\n",
    "        self.mouse_controller.press(Button.left)\n",
    "        self.dragging = True\n",
    "\n",
    "    def _stop_drag(self):\n",
    "        self.mouse_controller.release(Button.left)\n",
    "        self.dragging = False\n",
    "\n",
    "    def run(self):\n",
    "        cap = cv2.VideoCapture(self.camera_index)\n",
    "        if not cap.isOpened():\n",
    "            raise RuntimeError('Не удалось открыть камеру')\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, self.frame_size[0])\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, self.frame_size[1])\n",
    "\n",
    "        try:\n",
    "            while True and not self.exit:\n",
    "                success, frame = cap.read()\n",
    "                if not success:\n",
    "                    raise RuntimeError('Не удалось получить кадр с камеры')\n",
    "                frame = cv2.flip(frame, 1)\n",
    "                detections = self.predict_hands(frame)\n",
    "                self.process_detections(detections, frame.shape)\n",
    "        finally:\n",
    "            cap.release()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m detector = Gestura(\u001b[33m'\u001b[39m\u001b[33mYOLOv10n_gestures.pt\u001b[39m\u001b[33m'\u001b[39m, camera_index=\u001b[32m2\u001b[39m,\n\u001b[32m      2\u001b[39m                    buffer_size=\u001b[32m5\u001b[39m, scale=\u001b[32m0.2\u001b[39m, speed=\u001b[32m0.2\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mdetector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 110\u001b[39m, in \u001b[36mGestura.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    109\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.exit:\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m         success, frame = \u001b[43mcap\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    111\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m success:\n\u001b[32m    112\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mНе удалось получить кадр с камеры\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "detector = Gestura('YOLOv10n_gestures.pt', camera_index=2,\n",
    "                   buffer_size=5, scale=0.2, speed=0.2)\n",
    "detector.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.0.conv.weight: torch.float32\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('YOLOv10n_gestures.pt')\n",
    "\n",
    "for name, param in model.model.named_parameters():\n",
    "    print(f\"{name}: {param.dtype}\")\n",
    "    break  # уберите break, чтобы увидеть все параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
